# -*- coding: utf-8 -*-
"""webscrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19PjHsItt8E_uW4GgwBzPeqMYuDqaj6Yk
"""

import requests
from bs4 import BeautifulSoup
#Beurifulsoap genera un arbol de toda la pagina, por el cual nos podeos mover.

# Hacemos un pedido a la p치gina de wikipedia
URL = "https://latiendadelaempatia.com/"

# Guardamos el objeto que nos devuelve
respuesta = requests.get(URL)

html_obtenido = respuesta.text
soup = BeautifulSoup(html_obtenido,"html.parser")
divs = soup.find_all("div", class_= "eael-product-wrap")
for div in divs:
  print(div)
  print("")

imagenes = soup.find_all(src = True )
for imagen in imagenes:
    if imagen["src"].endswith(".png"):
            print(imagen)

import requests
from bs4 import BeautifulSoup
import csv

def webscrap(n):
  url = f"https://latiendadelaempatia.com/categoria-producto/mochilas/page/{n}/"
  response = requests.get(url)
  if response.status_code == 200:
      soup = BeautifulSoup(response.text, 'html.parser')
      divs = soup.find_all("div", class_="card-body text-center")
      a침o = []
      salario = []
      for div in divs:
          if (div.td is not None) and ("" in div.td.text):
              a침o = div.td.a_text(strip=True)
              salario = div.td.a_text(strip=True).replace("$", "")
              print(f"Producto: {a침o} Precio: {salario}")
              productos.append(producto)
              precios.append(precio)

from google.colab import drive
drive.mount('/content/drive')

import requests
from bs4 import BeautifulSoup
import csv

def webscrap(n):
  url = f"https://latiendadelaempatia.com/categoria-producto/alimentos-condimentos/page/{n}/"
  response = requests.get(url)
  if response.status_code == 200:
      soup = BeautifulSoup(response.text, 'html.parser')
      divs = soup.find_all("div", class_="content-wrapper")
      productos = []
      precios = []
      for div in divs:
          if (div.bdi is not None):
              producto = div.h3.get_text(strip=True)
              precio = div.bdi.get_text(strip=True).replace("$", "")
              print(f"Producto: {producto:<16} Precio: {precio}")
              productos.append(producto)
              precios.append(precio)
      if n == 1 :
       with open('alimentos y condimentos tienda de laempatia .csv', mode='w',newline='') as file:
          writer = csv.writer(file)
          writer.writerow(["Producto", "Precio"])
          for i in range(len(productos)):
              writer.writerow([productos[i], precios[i]])
      else:
        with open('alimentos y condimentos tienda de laempatia .csv', mode='a',newline='') as file:
            writer = csv.writer(file)
            writer.writerow(["Producto", "Precio"])
            for i in range(len(productos)):
                writer.writerow([productos[i], precios[i]])
for i in range(6):
  webscrap(i)

import requests
from bs4 import BeautifulSoup
import csv

def webscrap(n):
  url = f"https://latiendadelaempatia.com/categoria-producto/accesorios/page/{n}/"
  response = requests.get(url)
  if response.status_code == 200:
      soup = BeautifulSoup(response.text, 'html.parser')
      divs = soup.find_all("div", class_="content-wrapper")
      productos = []
      precios = []
      for div in divs:
          if (div.bdi is not None):
              producto = div.h3.get_text(strip=True)
              precio = div.bdi.get_text(strip=True).replace("$", "")
              print(f"Producto: {producto:<16} Precio: {precio}")
              productos.append(producto)
              precios.append(precio)
      if n == 1 :
       with open('accersorios tienda de laempatia .csv', mode='w',newline='') as file:
          writer = csv.writer(file)
          writer.writerow(["Producto", "Precio"])
          for i in range(len(productos)):
              writer.writerow([productos[i], precios[i]])
      else:
        with open('accersorios tienda de laempatia .csv', mode='a',newline='') as file:
            writer = csv.writer(file)
            writer.writerow(["Producto", "Precio"])
            for i in range(len(productos)):
                writer.writerow([productos[i], precios[i]])
for i in range(31):
  webscrap(i)

import requests
from bs4 import BeautifulSoup
import csv

def webscrap(n):
  url = f"https://www.amoratiempo.com/store/page/{n}/"
  response = requests.get(url)
  if response.status_code == 200:
      soup = BeautifulSoup(response.text, 'html.parser')
      divs = soup.find_all("div", class_="astra-shop-summary-wrap")
      productos = []
      precios = []
      for div in divs:
          if (div.bdi is not None):
              producto = div.h2.get_text(strip=True)
              precio = div.bdi.get_text(strip=True).replace("$", "")
              print(f"Producto: {producto:<16} Precio: {precio}")
              productos.append(producto)
              precios.append(precio)
      if n == 1 :
       with open('amoratiempo.csv', mode='w',newline='') as file:
          writer = csv.writer(file)
          writer.writerow(["Producto", "Precio"])
          for i in range(len(productos)):
              writer.writerow([productos[i], precios[i]])
      else:
        with open('amoratiempo.csv', mode='a',newline='') as file:
            writer = csv.writer(file)
            writer.writerow(["Producto", "Precio"])
            for i in range(len(productos)):
                writer.writerow([productos[i], precios[i]])
for i in range(3):
  webscrap(i)

import requests
from bs4 import BeautifulSoup
import csv

def webscrap(n):
  url = f"https://casanativadurani.com/index.php/tienda/page/{n}/"
  response = requests.get(url)
  if response.status_code == 200:
      soup = BeautifulSoup(response.text, 'html.parser')
      divs = soup.find_all("li")
      productos = []
      precios = []
      for li in divs:
          if (li.bdi is not None):
              producto = li.h2.get_text(strip=True)
              precio = li.bdi.get_text(strip=True).replace("$", "")
              print(f"Producto: {producto:<16} Precio: {precio}")
              productos.append(producto)
              precios.append(precio)
      if n == 1 :
       with open('casanativadurani.csv', mode='w',newline='') as file:
          writer = csv.writer(file)
          writer.writerow(["Producto", "Precio"])
          for i in range(len(productos)):
              writer.writerow([productos[i], precios[i]])
      else:
        with open('casanativadurani.csv', mode='a',newline='') as file:
            writer = csv.writer(file)
            writer.writerow(["Producto", "Precio"])
            for i in range(len(productos)):
                writer.writerow([productos[i], precios[i]])
for i in range(3):
  webscrap(i)

